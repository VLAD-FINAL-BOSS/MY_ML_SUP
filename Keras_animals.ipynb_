{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[{"file_id":"1kVm7RZfcPpGp34Ej4qJ3aFjagrt3ih8k","timestamp":1737522680688}]},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"Y9OMBfjJxUku"},"outputs":[],"source":["# импортируем необходимые пакеты\n","from keras.models import Sequential\n","from keras.layers import BatchNormalization\n","from keras.layers import Conv2D\n","from keras.layers import MaxPooling2D\n","from keras.layers import Activation\n","from keras.layers import Flatten\n","from keras.layers import Dropout\n","from keras.layers import Dense\n","from keras import backend as K\n"]},{"cell_type":"code","source":["class SmallVGGNet:\n","  @staticmethod\n","  def build(width, height, depth, classes):\n","    # инициализируем модель и размер входного изображения\n","    # для порядка каналов “channel_last” и размер канала\n","    model = Sequential()\n","    inputShape = (height, width, depth)\n","    chanDim = -1\n","\n","    # если мы используем порядок \"channels first\", обновляем\n","\t\t# входное изображение и размер канала\n","    if K.image_data_format() == \"channels_first\":\n","      inputShape = (depth, height, width)\n","      chanDim = 1\n","\n","\t\t# слои CONV => RELU => POOL\n","    model.add(Conv2D(32, (3, 3), padding=\"same\", input_shape=inputShape))\n","    model.add(Activation(\"relu\"))\n","    model.add(BatchNormalization(axis=chanDim))\n","    model.add(MaxPooling2D(pool_size=(2, 2)))\n","    model.add(Dropout(0.25))\n","\n","\t\t# слои (CONV => RELU) * 2 => POOL\n","    model.add(Conv2D(64, (3, 3), padding=\"same\"))\n","    model.add(Activation(\"relu\"))\n","    model.add(BatchNormalization(axis=chanDim))\n","    model.add(Conv2D(64, (3, 3), padding=\"same\"))\n","    model.add(Activation(\"relu\"))\n","    model.add(BatchNormalization(axis=chanDim))\n","    model.add(MaxPooling2D(pool_size=(2, 2)))\n","    model.add(Dropout(0.25))\n","\n","\t\t# (CONV => RELU) * 3 => POOL layer set\n","    model.add(Conv2D(128, (3, 3), padding=\"same\"))\n","    model.add(Activation(\"relu\"))\n","    model.add(BatchNormalization(axis=chanDim))\n","    model.add(Conv2D(128, (3, 3), padding=\"same\"))\n","    model.add(Activation(\"relu\"))\n","    model.add(BatchNormalization(axis=chanDim))\n","    model.add(Conv2D(128, (3, 3), padding=\"same\"))\n","    model.add(Activation(\"relu\"))\n","    model.add(BatchNormalization(axis=chanDim))\n","    model.add(MaxPooling2D(pool_size=(2, 2)))\n","    model.add(Dropout(0.25))\n","\n","\t\t# первый (и единственный) набор слоев FC => RELU\n","    model.add(Flatten())\n","    model.add(Dense(512))\n","    model.add(Activation(\"relu\"))\n","    model.add(BatchNormalization())\n","    model.add(Dropout(0.5))\n","\n","\t\t# классификатор softmax\n","    model.add(Dense(classes))\n","    model.add(Activation(\"softmax\"))\n","\n","\t\t# возвращаем собранную архитектуру нейронной сети\n","    return model"],"metadata":{"id":"g4yH6vDHyk2g"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from sklearn.preprocessing import LabelBinarizer\n","from sklearn.model_selection import train_test_split\n","from sklearn.metrics import classification_report\n","from tensorflow.keras.preprocessing.image import ImageDataGenerator\n","from keras.optimizers import SGD\n","from imutils import paths\n","import matplotlib.pyplot as plt\n","import numpy as np\n","import random\n","import pickle\n","import cv2\n","import os\n"],"metadata":{"id":"h5PI7DvR05es"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/drive')\n","data = []\n","labels = []\n","# берём пути к изображениям и рандомно перемешиваем\n","imagePaths = sorted(list(paths.list_images(\"/content/drive/MyDrive/animals\")))\n","random.seed(42)\n","random.shuffle(imagePaths)\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ycJZgkyz1M0L","executionInfo":{"status":"ok","timestamp":1737522546659,"user_tz":-180,"elapsed":28333,"user":{"displayName":"Влад Шмуткин","userId":"08156383992345727409"}},"outputId":"dd555d92-4fc4-4390-c381-efcd07f5e740"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}]},{"cell_type":"code","source":["# цикл по изображениям\n","for imagePath in imagePaths:\n","\t# загружаем изображение, меняем размер на 64x64 пикселей\n","\t# (требуемые размеры для SmallVGGNet), изменённое изображение\n","\t# добавляем в список\n","\timage = cv2.imread(imagePath)\n","\timage = cv2.resize(image, (64, 64))\n","\tdata.append(image)\n","\n","\t# извлекаем метку класса из пути к изображению и обновляем\n","\t# список меток\n","\tlabel = imagePath.split(os.path.sep)[-2]\n","\tlabels.append(label)\n"],"metadata":{"id":"xPEOQJOo2OQA","executionInfo":{"status":"error","timestamp":1737522670531,"user_tz":-180,"elapsed":123875,"user":{"displayName":"Влад Шмуткин","userId":"08156383992345727409"}},"outputId":"fa213f05-0b1b-46a4-f682-846622d87cb1","colab":{"base_uri":"https://localhost:8080/","height":220}},"execution_count":null,"outputs":[{"output_type":"error","ename":"KeyboardInterrupt","evalue":"","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-6-63209f4e92b2>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m         \u001b[0;31m# (требуемые размеры для SmallVGGNet), изменённое изображение\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m         \u001b[0;31m# добавляем в список\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m         \u001b[0mimage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimagePath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m         \u001b[0mimage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m64\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m64\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m         \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "]}]},{"cell_type":"code","source":["# масштабируем интенсивности пикселей в диапазон [0, 1]\n","data = np.array(data, dtype=\"float\") / 255.0\n","labels = np.array(labels)"],"metadata":{"id":"DQiz7KhB2-e_"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# разбиваем данные на обучающую и тестовую выборки, используя 75%\n","# данных для обучения и оставшиеся 25% для тестирования\n","(trainX, testX, trainY, testY) = train_test_split(data, labels, test_size=0.25, random_state=42)\n"],"metadata":{"id":"VdhmldLO3NwP"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# конвертируем метки из целых чисел в векторы (для 2х классов при\n","# бинарной классификации вам следует использовать функцию Keras\n","# “to_categorical” вместо “LabelBinarizer” из scikit-learn, которая\n","# не возвращает вектор)\n","lb = LabelBinarizer()\n","trainY = lb.fit_transform(trainY)\n","testY = lb.transform(testY)\n"],"metadata":{"id":"reXsqxFX3bE3"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# создаём генератор для добавления изображений\n","aug = ImageDataGenerator(rotation_range=30, width_shift_range=0.1,\n","\theight_shift_range=0.1, shear_range=0.2, zoom_range=0.2,\n","\thorizontal_flip=True, fill_mode=\"nearest\")\n","\n","# инициализируем нашу VGG-подобную сверточную нейросеть\n","model = SmallVGGNet.build(width=64, height=64, depth=3, classes=len(lb.classes_))\n","\n","# инициализируем скорость обучения, общее число эпох\n","# и размер пакета\n","INIT_LR = 0.01\n","EPOCHS = 100\n","BS = 32\n","\n","# компилируем модель с помощью SGD (для бинарной классификации\n","# следует использовать binary_crossentropy)\n","print(\"[INFO] training network...\")\n","#opt = SGD(lr=INIT_LR, decay=INIT_LR / EPOCHS)\n","model.compile(loss=\"categorical_crossentropy\", optimizer=\"sgd\", metrics=[\"accuracy\"])\n","\n","# обучаем нейросеть\n","H = model.fit_generator(aug.flow(trainX, trainY, batch_size=BS), validation_data=(testX, testY), steps_per_epoch=len(trainX) // BS, epochs=EPOCHS)\n","\n","# оцениваем нейросеть\n","print(\"[INFO] evaluating network...\")\n","predictions = model.predict(testX, batch_size=32)\n","print(classification_report(testY.argmax(axis=1),\n","\tpredictions.argmax(axis=1), target_names=lb.classes_))\n","\n","# строим графики потерь и точности\n","N = np.arange(0, EPOCHS)\n","plt.style.use(\"ggplot\")\n","plt.figure()\n","plt.plot(N, H.history[\"loss\"], label=\"train_loss\")\n","plt.plot(N, H.history[\"val_loss\"], label=\"val_loss\")\n","plt.plot(N, H.history[\"accuracy\"], label=\"train_acc\")\n","plt.plot(N, H.history[\"val_accuracy\"], label=\"val_acc\")\n"],"metadata":{"id":"7SO1BetC3tdh"},"execution_count":null,"outputs":[]}]}